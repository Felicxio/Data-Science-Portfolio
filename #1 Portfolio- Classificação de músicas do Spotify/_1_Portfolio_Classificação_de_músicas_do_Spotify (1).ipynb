{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Classifica√ß√£o de m√∫sicas do Spotify üéµ."
      ],
      "metadata": {
        "id": "TO0F4XOu3Xmk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sobre a base de dados:üé≤\n"
      ],
      "metadata": {
        "id": "iSZdNxtn3akb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este √© um conjunto de dados de faixas do Spotify em uma variedade de 125 g√™neros diferentes. Cada faixa possui alguns recursos de √°udio associados a ela."
      ],
      "metadata": {
        "id": "kxA9EicX3rwB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uso da base: üõ†Ô∏è\n",
        "O conjunto de dados pode ser usado para:\n",
        "\n",
        "\n",
        "\n",
        "1.   Construindo um sistema de recomenda√ß√£o com base em alguma entrada ou prefer√™ncia do usu√°rio\n",
        "2.   Finalidades de classifica√ß√£o com base em recursos de √°udio e g√™neros dispon√≠veis\n",
        "3.   Qualquer outro aplicativo que voc√™ possa imaginar. Sinta-se √† vontade para discutir!\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "H0K4CMSZ3tBQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Objetivo do nosso projeto:üéØ"
      ],
      "metadata": {
        "id": "zuoRZbfG4Dgp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este notebook contempla a cria√ß√£o de um modelo preditivo para classificar m√∫sicas lentas e agitadas utilizando a base de dados \"Spotify Tracks Dataset\" do Kaggle.\n",
        "\n",
        "O link desta base e mais detalhes se encontra em: https://www.kaggle.com/datasets/maharshipandya/-spotify-tracks-dataset"
      ],
      "metadata": {
        "id": "i1685TJf4GAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "BFydABwE47Mt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "df = pd.read_csv('/content/dataset.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "KzWpxt0-48aI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "TbAUVpM65hzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Criando a vari√°vel targetüéØ"
      ],
      "metadata": {
        "id": "4Ts29mmg6Bkc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "De acordo com a regra de neg√≥cio, a coluna valence √© uma medida de 0,0 a 1,0 que descreve a positividade musical transmitida por uma faixa. Faixas com alta val√™ncia soam mais positivas (por exemplo, feliz, alegre, euf√≥rica), enquanto faixas com baixa val√™ncia soam mais negativas (por exemplo, triste, deprimida, irritada). Para criar a nossa coluna alvo do modelo preditivo, vamos utizar a coluna \"valence\" para ser nosso crit√©rio de m√∫sicas agitadas ou lentas."
      ],
      "metadata": {
        "id": "ZB7rHum86EFQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Analisando a colune \"valence\" com o intuito de criar a vari√°vel de target\n",
        "plt.hist(df['valence'], bins=20, color='red', edgecolor='black')\n",
        "plt.xlabel('Valence')\n",
        "plt.ylabel('Frequ√™ncia')\n",
        "plt.title(\"Histograma da coluna Valence\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Z8lUhS4v5kSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uma an√°lise superficial do gr√°fico demonstra que ele est√° levemente deslocado para a esquerda, o que pode sinalizar que a maioria das m√∫sicas tem um ritmo mais lento, mas a discuss√£o ainda ir√° seguir adiante."
      ],
      "metadata": {
        "id": "U-pC4oOB6_aO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['valence'].describe() #caracter√≠sticas da coluna"
      ],
      "metadata": {
        "id": "SZrHHsKQ6tui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criando uma fun√ß√£o para categorizar os diferentes tipos de m√∫sica entre agitada e lenta a partir do limiar de valence."
      ],
      "metadata": {
        "id": "kza5lyZs7fr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def categorizar_valence(row):\n",
        "  if row['valence'] > 0.5:\n",
        "    return 'agitada'\n",
        "  else:\n",
        "    return 'lenta'\n",
        "#Agora iremos criar a nova coluna de 'target' utilizando a fun√ß√£o categorizar_Valence\n",
        "df['target'] = df.apply(categorizar_valence, axis=1)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "mcFUCnDb6zRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "id": "qKl43Kh28CLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Engineering üõ†Ô∏è"
      ],
      "metadata": {
        "id": "-shlriul8po2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como pr√≥ximo passo, vamos armazenar em um novo dataframe apenas as colunas necess√°rias para nossa classifica√ß√£o de m√∫sicas."
      ],
      "metadata": {
        "id": "NW7ewAWP8yIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "CnLmH6g18dXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_musica = df.drop(['Unnamed: 0', 'track_id'], axis = 1)\n",
        "df_musica.head()"
      ],
      "metadata": {
        "id": "d0U4uHQTAUJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tratando os dados categ√≥ricos üÖ∞Ô∏è"
      ],
      "metadata": {
        "id": "7w_aKb1mAzr2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LabelEncoder: Essa classe √© utilizada para codificar r√≥tulos de classes em n√∫meros inteiros. √â frequentemente usado quando se trabalha com algoritmos de aprendizado supervisionado que requerem r√≥tulos num√©ricos."
      ],
      "metadata": {
        "id": "pi7gFaycA3MD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_musica.head() #visualizando as colunas categ√≥ricas"
      ],
      "metadata": {
        "id": "8pSGz0fKCpKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def label_encoder_dataframe(df, columns_to_encode):\n",
        "  from sklearn.preprocessing import LabelEncoder\n",
        "  le = LabelEncoder()\n",
        "\n",
        "  for column in columns_to_encode:\n",
        "    if column in df.columns:\n",
        "      df[column] = le.fit_transform(df[column])\n",
        "    else:\n",
        "      print('A lista possui colunas que n√£o existem no DataFrame.')\n",
        "  return df\n",
        "\n",
        "colunas_a_codificar = ['artists', 'album_name', 'track_name', 'explicit', 'track_genre', 'target']\n",
        "label_encoder_dataframe(df_musica, colunas_a_codificar)\n",
        "df_musica.head() #o dataframe foi atualizado para ter apenas dados num√©ricos agora."
      ],
      "metadata": {
        "id": "ZZrYb23WAhOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analisando as vari√°veis que v√£o compor nosso modelo üìä"
      ],
      "metadata": {
        "id": "z-tlo-bUDcTW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fazendo um gr√°fico de correla√ß√£o com o seaborn."
      ],
      "metadata": {
        "id": "H1h_G5USDiXk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "_WnolecwC-pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correlation_matrix = df_musica.corr().round(2)\n",
        "\n",
        "fig,ax = plt.subplots(figsize=(12,10))\n",
        "sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', ax=ax);"
      ],
      "metadata": {
        "id": "heyXBAwHDmvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Poucas vari√°veis tem uma alta correla√ß√£o ao analisar o gr√°fico de calor, mas √© sempre bom lembrar que correla√ß√£o n√£o √© causalidade."
      ],
      "metadata": {
        "id": "SK4XX04wEQ8u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entendendo o equil√≠brio da target üéØ"
      ],
      "metadata": {
        "id": "ecMRdtv4Es7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Vamos verificar o equil√≠brio das classes na target\n",
        "round(df_musica['target'].value_counts(normalize=True)*100,2)"
      ],
      "metadata": {
        "id": "mFaQitGHEQTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set(df['target'])"
      ],
      "metadata": {
        "id": "dYlaigpHE_wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set(df_musica['target']) #apenas conferindo os valores que 0 e 1 representam: 0 = Agitada e 1 = Lenta"
      ],
      "metadata": {
        "id": "SCkWuuNkFIqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como as classes est√£o bem equilibradas n√£o vai ser necess√°rio realizar t√©cnicas adicionais para tratar um poss√≠vel desequil√≠brio, como oversampling e outras."
      ],
      "metadata": {
        "id": "nU5Y0Cz8Fa7R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Separando os dados em treino e teste üîÑ"
      ],
      "metadata": {
        "id": "xKfXqTVtFs8X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora vamos criar um modelo supervisionado."
      ],
      "metadata": {
        "id": "4_6Aj7PLFuJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_musica.columns"
      ],
      "metadata": {
        "id": "Sii68WsFFOSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#separando os dados em treino e teste (m√©todo hold out - divis√£o, treinamento e avalia√ß√£o)\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df_musica[['popularity', 'duration_ms', 'danceability', 'energy', 'loudness', 'acousticness', 'instrumentalness', 'liveness', 'track_genre']]\n",
        "y = df_musica['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n"
      ],
      "metadata": {
        "id": "0U1S0qDNF3IP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape, X_test.shape)"
      ],
      "metadata": {
        "id": "XA2nIOMQGwvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalizando os dados üìè"
      ],
      "metadata": {
        "id": "EK3WSQXjG3Gy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ao aplicar o MinMaxScaler, todos os valores dos dados ser√£o transformados para o intervalo entre 0 e 1, onde o valor m√≠nimo ser√° 0 e o valor m√°ximo ser√° 1. Essa t√©cnica √© especialmente √∫til quando os algoritmos de aprendizado de m√°quina s√£o sens√≠veis √† escala dos dados.\n",
        "\n",
        "Por que aplicamos a normaliza√ß√£o dos dados com as bases j√° separadas em treino e teste? ü§î Se aplicarmos normaliza√ß√µes antes de dividir em conjuntos de treino e teste, podemos acabar introduzindo informa√ß√µes do conjunto de teste no conjunto de treino. Isso pode levar a uma avalia√ß√£o otimista do desempenho do modelo, uma vez que o modelo ter√° visto parte dos dados de teste durante o treinamento. Este tipo de problema tamb√©m √© chamado de Data Leak (vazamento de dados)."
      ],
      "metadata": {
        "id": "9hicmCjjG53b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import ScalarType\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "#Criar uma inst√¢ncia do MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "scaler.fit(X_train) #fazemos o fit apenas na base de treinamento para evitar data leak\n",
        "\n",
        "X_train_escalonado = scaler.transform(X_train)\n",
        "X_test_escalonado = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "4_F4X306G1NE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Criando uma fun√ß√£o para executar modelos de machine learning üöÄ"
      ],
      "metadata": {
        "id": "c1RbYF_qJl7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def roda_modelo(modelo):\n",
        "\n",
        "    from sklearn.metrics import roc_curve, roc_auc_score, classification_report\n",
        "\n",
        "    # Treinando modelo com os dados de treino\n",
        "    modelo.fit(X_train_escalonado, y_train)\n",
        "\n",
        "    # Calculando a probabilidade e calculando o AUC\n",
        "    prob_predic = modelo.predict_proba(X_test_escalonado) # obter as probabilidades associadas √†s classes previstas para cada inst√¢ncia de dados\n",
        "    auc = roc_auc_score(y_test, prob_predic[:,1])\n",
        "    print(f\"AUC {auc}\")\n",
        "\n",
        "    # Fazendo a predicao dos dados de teste e calculando o classification report\n",
        "    predicao = modelo.predict(X_test_escalonado)\n",
        "    print(\"\\nClassification Report\")\n",
        "    print(classification_report(y_test, predicao))\n",
        "\n",
        "    print(\"\\nRoc Curve\\n\")\n",
        "    # Fazer previs√µes de probabilidades\n",
        "    y_pred_probs = modelo.predict_proba(X_test_escalonado)[:, 1]\n",
        "\n",
        "    # Calcular a curva ROC\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)\n",
        "\n",
        "    # Calcular a AUC (√°rea sob a curva ROC)\n",
        "    auc = roc_auc_score(y_test, y_pred_probs)\n",
        "\n",
        "    # Plotar a curva ROC\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, color='blue', label=f'ROC curve (AUC = {auc:.2f})') # linewidth\n",
        "    plt.plot([0, 1], [0, 1], color='gray',linestyle='--')\n",
        "    plt.xlabel('Taxa de Falso Positivo')\n",
        "    plt.ylabel('Taxa de Verdadeiro Positivo')\n",
        "    plt.title('Curva ROC')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    # Converter probabilidades em classes preditas (0 ou 1)\n",
        "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
        ""
      ],
      "metadata": {
        "id": "yZHqZ5OhJnDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regress√£o log√≠stica"
      ],
      "metadata": {
        "id": "XqUrXaFOLUSF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O modelo se baseia em uma fun√ß√£o log√≠stica, que transforma as vari√°veis independentes em uma probabilidade entre 0 e 1. Para novas entradas de dados, o modelo calcula a probabilidade do evento bin√°rio ocorrer."
      ],
      "metadata": {
        "id": "NgT52ypDLYDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "modelo_logistico = LogisticRegression()\n",
        "roda_modelo(modelo_logistico)"
      ],
      "metadata": {
        "id": "D1sZmgUpLWtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analisando o f1-score e as outras m√©tricas de avalia√ß√£o, √© poss√≠vel concluir que esse m√©todo de regress√£o n√£o ficou bem adequado com a constru√ß√£o de um bom modelo com os dados selecionados."
      ],
      "metadata": {
        "id": "EEhFolYnLtS1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KNN (K-Nearest Neighbors)"
      ],
      "metadata": {
        "id": "CswNvMluL7b6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para um novo ponto de dados, o KNN identifica os K pontos mais pr√≥ximos (vizinhos) no conjunto de treinamento. A classe do novo ponto √© a classe mais frequente entre os K vizinhos."
      ],
      "metadata": {
        "id": "EywCAtL4L_VE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "modelo_knn = KNeighborsClassifier(n_neighbors=3)\n",
        "roda_modelo(modelo_knn)\n",
        ""
      ],
      "metadata": {
        "id": "m9pot1rCLs3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Da mesma forma que o modelo de regress√£o, esse n√£o ficou t√£o satisfat√≥rio."
      ],
      "metadata": {
        "id": "1i-i317YMLyK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Florest"
      ],
      "metadata": {
        "id": "Oa_bA4M0MQeI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O Random Forest Classifier √© um algoritmo de ensemble learning, que combina v√°rios modelos para melhorar a performance. O modelo cria uma floresta de √°rvores de decis√£o, onde cada √°rvore √© treinada em um subconjunto aleat√≥rio dos dados (bootstrap). A classe final do novo ponto de dados √© a classe mais votada pelas √°rvores da floresta."
      ],
      "metadata": {
        "id": "FSEZ_X9uMS1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "modelo_random_forest = RandomForestClassifier(max_depth=7, n_estimators= 100)\n",
        "roda_modelo(modelo_random_forest)"
      ],
      "metadata": {
        "id": "E4LM4LjWMVqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Est√° melhorando aos poucos, mas mesmo assim ainda n√£o tem um rendimento ideal. Vamos utilizar Grid Search para alterar par√¢metros."
      ],
      "metadata": {
        "id": "rSPWmtL-MltN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testando novos par√¢metros com Grid Search"
      ],
      "metadata": {
        "id": "Gw4e4fBaMwJu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Defina os par√¢metros a serem testados\n",
        "param_grid = {\n",
        "    \"n_estimators\": [100, 200, 300],\n",
        "    \"max_depth\": [5, 10, 15]\n",
        "}\n",
        "\n",
        "# GridSearchCV\n",
        "grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5, scoring='f1', n_jobs=1)\n",
        "\n",
        "# Ajuste o modelo ao conjunto de dados\n",
        "grid_search.fit(X_train_escalonado, y_train)\n",
        "\n",
        "rf_params = grid_search.best_params_\n",
        "print(\"Melhores hiperpar√¢metros:\", rf_params)"
      ],
      "metadata": {
        "id": "AXg77inoM2zO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Melhores Hiperpar√¢metros:{'max_depth':15, 'n_estimators':300}"
      ],
      "metadata": {
        "id": "CYTkPWRENMF-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testando agora com esses par√¢metros"
      ],
      "metadata": {
        "id": "hw-shUvXNkHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo_random_forest = RandomForestClassifier(max_depth=15, n_estimators= 300)\n",
        "roda_modelo(modelo_random_forest)"
      ],
      "metadata": {
        "id": "4EF9HxigNjYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8e82bcf5"
      },
      "source": [
        "# Tentando novos par√¢metros ajustados manualmente\n",
        "modelo_random_forest_manual = RandomForestClassifier(n_estimators=500, max_depth=20, min_samples_split=5, random_state=42)\n",
        "roda_modelo(modelo_random_forest_manual)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a22f900"
      },
      "source": [
        "Neste exemplo, aumentamos o `n_estimators` (n√∫mero de √°rvores) para 500, a `max_depth` (profundidade m√°xima das √°rvores) para 20 e adicionamos `min_samples_split=5`. Esses s√£o apenas alguns ajustes que poderiam ser testados manualmente. O `random_state` foi adicionado para garantir a reprodutibilidade dos resultados."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ainda n√£o est√° pr√≥ximo de uma acur√°cia de 90%, mas melhorou bastante. Provavelmente √© melhor trabalhar com mais hiperpar√¢metros ainda para melhorar esse modelo."
      ],
      "metadata": {
        "id": "iTOjp5vMOJy-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testando o Modelo ‚úÖ"
      ],
      "metadata": {
        "id": "EB55v3ZTN6zT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "novos_dados = pd.read_excel(\"novos_dados.xlsx\")\n",
        "base_original = pd.read_excel(\"novos_dados.xlsx\")\n",
        "\n",
        "#Criando a pipeline\n",
        "coluna = ['track_genre']\n",
        "label_encoder_dataframe(novos_dados, coluna)\n",
        "novos_dados = scaler.transform(novos_dados)\n",
        "\n",
        "# Realize a previs√£o usando o modelo Random Forest treinado\n",
        "previsoes = modelo_random_forest_manual.predict(novos_dados)\n",
        "\n",
        "# Obtendo o predict\n",
        "def mapear_valor(valores):\n",
        "    resultados = []\n",
        "    for valor in valores:\n",
        "        if valor == 0:\n",
        "            resultados.append('M√∫sica agitada')\n",
        "        elif valor == 1:\n",
        "            resultados.append('M√∫sica lenta')\n",
        "        else:\n",
        "            resultados.append('Desconhecido')\n",
        "    return np.array(resultados)\n",
        "\n",
        "base_original['target'] = mapear_valor(previsoes)\n",
        "base_original.head()"
      ],
      "metadata": {
        "id": "YdD5LLHROEJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Com o modelo √© poss√≠vel ver o resultado a partir do track_genre em conjunto com o target, sendo poss√≠vel visualizar se √© uma m√∫sica agitada ou lenta."
      ],
      "metadata": {
        "id": "Sn9oTdakSZVM"
      }
    }
  ]
}